{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all csv files into respective dataframes\n",
    "BTC_df = pd.read_csv('..\\\\Project_2_BTC_Price_Modeling\\csv_files\\BTC-USD (3).csv')\n",
    "\n",
    "AUD_df = pd.read_csv('..\\\\Project_2_BTC_Price_Modeling\\csv_files\\AUDUSD=X.csv')\n",
    "EUR_df = pd.read_csv('..\\\\Project_2_BTC_Price_Modeling\\csv_files\\EURUSD=X.csv')\n",
    "GBP_df = pd.read_csv('..\\\\Project_2_BTC_Price_Modeling\\csv_files\\GBPUSD=X.csv')\n",
    "JPY_df = pd.read_csv('..\\\\Project_2_BTC_Price_Modeling\\csv_files\\JPY=X.csv')\n",
    "\n",
    "SOL_df = pd.read_csv('..\\\\Project_2_BTC_Price_Modeling\\csv_files\\SOL-USD.csv')\n",
    "ETH_df = pd.read_csv('..\\\\Project_2_BTC_Price_Modeling\\csv_files\\ETH-USD.csv')\n",
    "LTC_df = pd.read_csv('..\\\\Project_2_BTC_Price_Modeling\\csv_files\\LTC-USD.csv')\n",
    "DOGE_df = pd.read_csv('..\\\\Project_2_BTC_Price_Modeling\\csv_files\\DOGE-USD.csv')\n",
    "\n",
    "DGS10_df = pd.read_csv('..\\\\Project_2_BTC_Price_Modeling\\csv_files\\DGS10 (3).csv')\n",
    "DTB3_df = pd.read_csv('..\\\\Project_2_BTC_Price_Modeling\\csv_files\\DTB3 (1).csv')\n",
    "\n",
    "USEP_df = pd.read_csv(r'..\\\\Project_2_BTC_Price_Modeling\\csv_files\\USEPUINDXD.csv')\n",
    "GEP_df = pd.read_csv('..\\\\Project_2_BTC_Price_Modeling\\csv_files\\GEPUCURRENT.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-15</td>\n",
       "      <td>424.102997</td>\n",
       "      <td>398.821014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-22</td>\n",
       "      <td>399.100006</td>\n",
       "      <td>377.181000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>376.928009</td>\n",
       "      <td>320.510010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-10-06</td>\n",
       "      <td>320.389008</td>\n",
       "      <td>378.549011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-10-13</td>\n",
       "      <td>377.920990</td>\n",
       "      <td>389.545990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open       Close\n",
       "0  2014-09-15  424.102997  398.821014\n",
       "1  2014-09-22  399.100006  377.181000\n",
       "2  2014-09-29  376.928009  320.510010\n",
       "3  2014-10-06  320.389008  378.549011\n",
       "4  2014-10-13  377.920990  389.545990"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove High, low, Adj Close and volume column from BTC dataframe\n",
    "\n",
    "BTC_df = BTC_df.drop([\"High\",\"Low\",\"Volume\", \"Adj Close\"], axis=1)\n",
    "\n",
    "BTC_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 522 entries, 0 to 521\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Date              522 non-null    object \n",
      " 1   BTC Open          521 non-null    float64\n",
      " 2   BTC Close         521 non-null    float64\n",
      " 3   BTC Return Rate   521 non-null    float64\n",
      " 4   BTC Return Class  522 non-null    int64  \n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 20.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#Create a return rate column, and another column that encodes for positive (1) and negative returns (0) rename to specify BTC data\n",
    "BTC_df['BTC Return Rate'] = (BTC_df['Close'] - BTC_df['Open']) / BTC_df['Open']\n",
    "\n",
    "BTC_df['BTC Return Class'] = BTC_df['BTC Return Rate'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "#rename to specify BTC data\n",
    "\n",
    "BTC_rename_df = BTC_df.rename(columns={'Open':'BTC Open','Close':'BTC Close'})\n",
    "BTC_rename_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unecessary rows from forex data\n",
    "\n",
    "AUD_clean_df = AUD_df.drop([\"High\",\"Low\",\"Volume\", \"Adj Close\"], axis=1)\n",
    "EUR_clean_df = EUR_df.drop([\"High\",\"Low\",\"Volume\", \"Adj Close\"], axis=1)\n",
    "GBP_clean_df = GBP_df.drop([\"High\",\"Low\",\"Volume\", \"Adj Close\"], axis=1)\n",
    "JPY_clean_df = JPY_df.drop([\"High\",\"Low\",\"Volume\", \"Adj Close\"], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create return rate columns for FOREX\n",
    "\n",
    "AUD_clean_df['AUD Return Rate'] = (AUD_clean_df['Close'] - AUD_clean_df['Open']) /AUD_clean_df['Open']\n",
    "EUR_clean_df['EUR Return Rate'] = (EUR_clean_df['Close'] - EUR_clean_df['Open']) /EUR_clean_df['Open']\n",
    "GBP_clean_df['GBP Return Rate'] = (GBP_clean_df['Close'] - GBP_clean_df['Open']) /GBP_clean_df['Open']\n",
    "JPY_clean_df['JPY Return Rate'] = (JPY_clean_df['Close'] - JPY_clean_df['Open']) /JPY_clean_df['Open']\n",
    "\n",
    "AUD_rename_df = AUD_clean_df.rename(columns={'Open':'AUD Open','Close':'AUD Close'})\n",
    "EUR_rename_df = EUR_clean_df.rename(columns={'Open':'EUR Open','Close':'EUR Close'})\n",
    "GBP_rename_df = GBP_clean_df.rename(columns={'Open':'GBP Open','Close':'GBP Close'})\n",
    "JPY_rename_df = JPY_clean_df.rename(columns={'Open':'JPY Open','Close':'JPY Close'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 520 entries, 0 to 519\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Date    520 non-null    object \n",
      " 1   DGS10   520 non-null    float64\n",
      " 2   DTB3    520 non-null    float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 12.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#Combine treasury bills dataframe, and divide by 100 to reduce to decimals instead of percentages\n",
    "combined_treasuries_df = DGS10_df.merge(DTB3_df, on='Date',how='outer')\n",
    "combined_treasuries_df['DGS10'] = combined_treasuries_df['DGS10']/100\n",
    "combined_treasuries_df['DTB3'] = combined_treasuries_df['DTB3']/100\n",
    "combined_treasuries_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 522 entries, 0 to 521\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Date             522 non-null    object \n",
      " 1   AUD Return Rate  522 non-null    float64\n",
      " 2   EUR Return Rate  522 non-null    float64\n",
      " 3   GBP Return Rate  522 non-null    float64\n",
      " 4   JPY Return Rate  522 non-null    float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 20.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#Merge FOREX data frames\n",
    "\n",
    "combined_currency_ex_df = AUD_rename_df.merge(EUR_rename_df, on='Date', how='outer').merge(GBP_rename_df, on='Date', how='outer').merge(JPY_rename_df, on='Date', how='outer')\n",
    "clean_currency_df = combined_currency_ex_df.drop(['AUD Open','AUD Close','EUR Open','EUR Close','GBP Open','GBP Close','JPY Open','JPY Close'], axis=1)\n",
    "clean_currency_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>USEPUINDXD</th>\n",
       "      <th>GEPUCURRENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-15</td>\n",
       "      <td>67.894286</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-22</td>\n",
       "      <td>58.347143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>55.678571</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-10-06</td>\n",
       "      <td>72.465714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-10-13</td>\n",
       "      <td>59.967143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  USEPUINDXD  GEPUCURRENT\n",
       "0  2014-09-15   67.894286          NaN\n",
       "1  2014-09-22   58.347143          NaN\n",
       "2  2014-09-29   55.678571          NaN\n",
       "3  2014-10-06   72.465714          NaN\n",
       "4  2014-10-13   59.967143          NaN"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Merge Uncertainty index\n",
    "combined_uncertainty_df =  USEP_df.merge(GEP_df, on = \"DATE\", how='outer')\n",
    "combined_uncertainty_rename_df = combined_uncertainty_df.rename(columns={\"DATE\":'Date'})\n",
    "combined_uncertainty_rename_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "DateParseError",
     "evalue": "Unknown datetime string format, unable to parse: DATE, at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Function to repeat Global Economic uncertainty values based on days in the month\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m GEP_df\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepeat_values_based_on_days\u001b[39m(df):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Create a new DataFrame to store the repeated values\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     repeated_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n",
      "File \u001b[1;32mc:\\Users\\dyllan\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1144\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         result \u001b[38;5;241m=\u001b[39m _convert_and_box_cache(argc, cache_array)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1144\u001b[0m         result \u001b[38;5;241m=\u001b[39m convert_listlike(argc, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1146\u001b[0m     result \u001b[38;5;241m=\u001b[39m convert_listlike(np\u001b[38;5;241m.\u001b[39marray([arg]), \u001b[38;5;28mformat\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\dyllan\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:490\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[1;32m--> 490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    491\u001b[0m     arg,\n\u001b[0;32m    492\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m    493\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[0;32m    494\u001b[0m     utc\u001b[38;5;241m=\u001b[39mutc,\n\u001b[0;32m    495\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    496\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m )\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[0;32m    502\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(result, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[1;32mc:\\Users\\dyllan\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2346\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, allow_object)\u001b[0m\n\u001b[0;32m   2343\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[0;32m   2344\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[1;32m-> 2346\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m tslib\u001b[38;5;241m.\u001b[39marray_to_datetime(\n\u001b[0;32m   2347\u001b[0m     data,\n\u001b[0;32m   2348\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   2349\u001b[0m     utc\u001b[38;5;241m=\u001b[39mutc,\n\u001b[0;32m   2350\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   2351\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[0;32m   2352\u001b[0m )\n\u001b[0;32m   2354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2355\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m   2356\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[0;32m   2357\u001b[0m     \u001b[38;5;66;03m# Return i8 values to denote unix timestamps\u001b[39;00m\n\u001b[0;32m   2358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m), tz_parsed\n",
      "File \u001b[1;32mtslib.pyx:403\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:552\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:517\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mconversion.pyx:546\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:331\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:660\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDateParseError\u001b[0m: Unknown datetime string format, unable to parse: DATE, at position 0"
     ]
    }
   ],
   "source": [
    "# Function to repeat Global Economic uncertainty values based on days in the month\n",
    "\n",
    "GEP_df= pd.to_datetime(['DATE'])\n",
    "\n",
    "def repeat_values_based_on_days(df):\n",
    "    # Create a new DataFrame to store the repeated values\n",
    "    repeated_df = pd.DataFrame()\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        # Extract the year and month\n",
    "        year = row['DATE'].year\n",
    "        month = row['DATE'].month\n",
    "        \n",
    "        # Get the number of days in the month\n",
    "        num_days = pd.Period(f\"{year}-{month}\").days_in_month\n",
    "        \n",
    "        # Repeat the value for the number of days\n",
    "        repeated_values = pd.DataFrame({\n",
    "            'DATE': pd.date_range(start=f'{year}-{month}-01', periods=num_days, freq='D'),\n",
    "            'GEPUCURRENT': np.repeat(row['GEPUCURRENT'], num_days)\n",
    "        })\n",
    "        \n",
    "        # Append to the repeated_df\n",
    "        repeated_df = pd.concat([repeated_df, repeated_values])\n",
    "    \n",
    "    return repeated_df.reset_index(drop=True)\n",
    "\n",
    "# Apply the function\n",
    "result_df = repeat_values_based_on_days(GEP_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
